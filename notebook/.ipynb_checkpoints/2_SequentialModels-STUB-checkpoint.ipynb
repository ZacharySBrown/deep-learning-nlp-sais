{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import getpass\n",
    "\n",
    "from traitlets.config.manager import BaseJSONConfigManager\n",
    "path = \"/Users/{}/anaconda3/envs/rise_latest/etc/jupyter/nbconfig\".format(getpass.getuser())\n",
    "cm = BaseJSONConfigManager(config_dir=path)\n",
    "o = cm.update(\"livereveal\", {\n",
    "              \"theme\": \"sky\",\n",
    "              \"transition\": \"fade\",\n",
    "              \"start_slideshow_at\": \"selected\",\n",
    "})\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vectorization and Classification with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topics\n",
    "* RNN Encoding for Text Classification\n",
    "* Recurrent Neural Networks\n",
    "* Word Embeddings\n",
    "* Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-class Document Classification\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"src/Shape_of_NLP_Problems_2.png?\" alt=\"perceptron\" style=\"width:968px\">\n",
    "</center>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Text Vectorization with Recurrent Neural Networks\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"src/Shape_of_NLP_Problems_6.png?\" alt=\"perceptron\" style=\"width:968px\">\n",
    "</center>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Networks\n",
    "<center>\n",
    "<img src=\"src/0_rnn.png?\" alt=\"perceptron\" style=\"height:400px\">\n",
    "</center> \n",
    "<font size=\"-1\">\n",
    "Images graciously sourced from <a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a> by Christopher Olah\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Networks (unrolled)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"src/1_rnn.png?\" alt=\"perceptron\" style=\"height:300px\">\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vanilla Recurrent Neural Networks\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"src/0_lstm.png?\" alt=\"perceptron\" style=\"height:300px\">\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Long Short-term Memory (LSTM) Networks\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"src/1_lstm.png?\" alt=\"perceptron\" style=\"height:300px\">\n",
    "</center> \n",
    "\n",
    "<font size=\"-1\">\n",
    "For a deeper dive into the necessity for and implementation of LSTM networks, see <a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a> by Christopher Olah\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encoding a Sequence to a single Vector\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"src/0_rnn_encoding.png?\" alt=\"perceptron\" style=\"height:300px\">\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequence Classification\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"src/0a_rnn_encoding.png?\" alt=\"perceptron\" style=\"height:300px\">\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequence Classification\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"src/0b_rnn_encoding.png?\" alt=\"perceptron\" style=\"height:300px\">\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<h2> Wait, what about the inputs to the RNN??</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word Embeddings: Bag-of-Words vs. Dense Representations \n",
    "<br>\n",
    "<center>\n",
    "<img src=\"src/0_bow_vs_dense.png?\" alt=\"bow_vs_dense\" style=\"height:400px\">\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LSTM Text Encoding and Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn import Linear, Embedding, RNN, GRU, LSTM\n",
    "from torch.nn import Sigmoid, LogSoftmax\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss, NLLLoss, CrossEntropyLoss\n",
    "from string import punctuation\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data into a DataFrame\n",
    "data = pd.read_pickle('../data/2_r8.pkl')\n",
    "\n",
    "# Definne a simple convenience function for cleaning the strings\n",
    "def clean_text(text):\n",
    "    return \"\".join([c for c in text.lower() if c not in punctuation])\n",
    "\n",
    "# Clean the string labels\n",
    "data['text_cleaned'] = data['text'].map(clean_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# first start by splitting the strings,\n",
    "# then determining all of the unique words in the corpus\n",
    "text_split = data['text_cleaned'].map(lambda x: x.split())\n",
    "all_words = set(list(itertools.chain.from_iterable(text_split)))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "# next, determing all of the unique labels, \n",
    "all_labels = list(data['label'].unique())\n",
    "label_size = len(all_labels)\n",
    "\n",
    "# create two lookups that translate word <-> integer index\n",
    "# note that this is similar the the underlying representation\n",
    "# of a simple count vectorizer\n",
    "word2idx = {word: idx for idx, word in enumerate(all_words)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "# create a similar lookup for the labels label <-> integer\n",
    "label2idx = {word: idx for idx, word in enumerate(all_labels)}\n",
    "idx2label = {idx: word for word, idx in label2idx.items()}\n",
    "\n",
    "# encode both the text and label as integers\n",
    "data['text_encoded'] = data['text_cleaned'].map(lambda x: [word2idx[word] for word in x.split()])\n",
    "data['label_encoded'] = data['label'].map(lambda x: [label2idx[word] for word in x.split()])\n",
    "\n",
    "# grab the labels and features\n",
    "# and create training and testing sets\n",
    "labels = data['label_encoded'].values\n",
    "features = data['text_encoded']\n",
    "train_data, test_data = train_test_split(list(zip(features, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# let's define the pieces that we'll \n",
    "# need for the model\n",
    "\n",
    "# we'll start with an embedding layer\n",
    "# the input size is the size of our vocabulary \n",
    "# (we'll need a row for every word in the input)\n",
    "# and the output size is the dimension that\n",
    "# we'll want for our word vectors\n",
    "# TODO: CREATE AN EMBEDDING LAYER\n",
    "\n",
    "# once we've converted our tokens to \n",
    "# vectors via an embedding layer, we'll\n",
    "# want to run a sequence of these vectors\n",
    "# through an LSTM layer. The input size of\n",
    "# the LSTM is our embedding dimension, \n",
    "# and the hidden dimension can be chosen by us\n",
    "# TODO: CREATE AN LSTM\n",
    "\n",
    "# because the forward pass of the LSTM\n",
    "# requires the hidden state from the previous\n",
    "# step as input, we'll have to initialize\n",
    "# the hidden state vectors. this will\n",
    "# need to be done at the beginning of each iteration\n",
    "# before we run any new sequence through the LSTM\n",
    "# TODO: CREATE A TUPLE CONTAINING THE HIDDEN\n",
    "# AND CELL STATES INITIALIZED TO ZEROS\n",
    "\n",
    "# we'll be taking the last output of \n",
    "# the LSTM sequence which will be the \n",
    "# same dimension as the hidden layer.\n",
    "# We'll then need a single linear layer \n",
    "# to act as a classifier. The input size \n",
    "# should then be the same as the hidden dim \n",
    "# of the LSTM, and the output size should be \n",
    "# the same as out number of classes for the \n",
    "# classification task\n",
    "# TODO: CREATE A LINEAR LAYER TO TRANSFORM THE LSTM OUTPUT\n",
    "\n",
    "# lastly, we'll want to normalize the final output\n",
    "# to a softmax distribution\n",
    "# CREATE A LOGSOFTMAX TRANSFORMER TO CONVERT THE \n",
    "# LINEAR OUTPUT TO A LOGSOFTMAX DISTRIBUTION\n",
    "\n",
    "# we'll want to use NLLLoss for this situation\n",
    "# TODO: CREATE AN INSTANCE OF THE NLLLOSS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# start by taking a sample feature and sample target\n",
    "f = features[0]\n",
    "t = labels[0]\n",
    "\n",
    "# cast them to torch tensors\n",
    "X = #TODO\n",
    "y = # TODO\n",
    "print(\"Integer Feature Sequence Shape:\", X.shape)\n",
    "print(\"Integer Target Shape:\", y.shape)\n",
    "\n",
    "# pass the sequence through the embedding layer\n",
    "embedded_sequence = #TODO\n",
    "print(\"Embedding Sequence Shape:\", embedded_sequence.shape)\n",
    "\n",
    "# the LSTM takes input tensors of shape:\n",
    "# (seq_len, batch_size, input_dimension)\n",
    "# so we'll use the .view() method\n",
    "# of the torch tensor to reshape the embedding\n",
    "# and insert an additional dimension\n",
    "embedded_sequence = #TODO\n",
    "\n",
    "# Pass the embedded sequence through the lstm layer\n",
    "lstm_output, lstm_hidden = lstm(embedded_sequence, lstm_hidden)\n",
    "print(\"LSTM Output Shape:\", lstm_output.shape)\n",
    "\n",
    "# retain only the final output state\n",
    "# of the lstm\n",
    "final_output = #TODO\n",
    "print(\"Linear Layer Input Shape:\", final_output.shape)\n",
    "\n",
    "# run the final output through the linear layer\n",
    "linear_output = #TODO\n",
    "print(\"Linear Output Shape:\", linear_output.shape)\n",
    "\n",
    "# run the linear output through the softmax activation\n",
    "softmax_output = #TODO\n",
    "print(\"Softmax Output Shape:\", softmax_output.shape)\n",
    "print(\"Target Shape:\", y.shape)\n",
    "\n",
    "# calculate the loss w.r.t. the target\n",
    "loss = #TODO\n",
    "print(\"Loss Value:\", loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from modules.classification import *\n",
    "\n",
    "model = rnn_classifier(vocab_size = vocab_size, \n",
    "                       embedding_dim=100, \n",
    "                       hidden_dim=50, \n",
    "                       output_dim=label_size, \n",
    "                       batch_size=1)\n",
    "\n",
    "optim = SGD(params=model.parameters(), lr=0.01)\n",
    "criterion = NLLLoss()\n",
    "\n",
    "for i in range(10):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for it, example in enumerate(train_data):\n",
    "\n",
    "        f, t = example\n",
    "        X = torch.LongTensor(f[:32]) # we'll only take the first 32 elements in the sequence\n",
    "        y = torch.LongTensor(t)\n",
    "        \n",
    "        model.hidden = model.init_hidden()\n",
    "        output = model.forward(X)\n",
    "        optim.zero_grad()\n",
    "        prediction = torch.argmax(output)\n",
    "        loss = criterion(output, y)\n",
    "        total_loss += loss.data.numpy()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for example in test_data:\n",
    "        optim.zero_grad()\n",
    "        f, t = example\n",
    "        X = torch.LongTensor(f[:32]) # we're only using the first 32 elements in the sequence\n",
    "        y = torch.LongTensor(t)\n",
    "\n",
    "        model.hidden = model.init_hidden()\n",
    "        output = model.forward(X)\n",
    "        prediction = torch.argmax(output)\n",
    "\n",
    "        y_true.append(y.data.numpy()[0])\n",
    "        y_pred.append(torch.argmax(output.data).numpy())\n",
    "\n",
    "        a = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    total_loss /= (it + 1)\n",
    "\n",
    "    print(\"Loss: {:.2f}, Validation Accuracy: {:.2f}\".format(total_loss, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
